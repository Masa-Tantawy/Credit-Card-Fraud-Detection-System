{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d698609",
   "metadata": {
    "id": "4d698609"
   },
   "outputs": [],
   "source": [
    "## Ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "###\n",
    "\n",
    "%matplotlib inline \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "EydkDcS7iWVN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EydkDcS7iWVN",
    "outputId": "30c4da32-d314-47e0-f33f-6a96a6e5cfac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09f59326",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09f59326",
    "outputId": "f4cd0e45-f1b5-4c93-b552-e6df55bf846a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1388969, 83) (462990, 83) (1388969, 1) (462990, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train= pd.read_csv(\"/content/drive/MyDrive/University/Spring 2023/ML Project/Phase 3/Phase 3 Models/xtrain.csv\")\n",
    "y_train= pd.read_csv(\"/content/drive/MyDrive/University/Spring 2023/ML Project/Phase 3/Phase 3 Models/ytrain.csv\")\n",
    "x_test=pd.read_csv(\"/content/drive/MyDrive/University/Spring 2023/ML Project/Phase 3/Phase 3 Models/xtest.csv\")\n",
    "y_test= pd.read_csv(\"/content/drive/MyDrive/University/Spring 2023/ML Project/Phase 3/Phase 3 Models/ytest.csv\")\n",
    "\n",
    "x_train= x_train.iloc[:,1:]\n",
    "x_test= x_test.iloc[:,1:]\n",
    "y_train= y_train.iloc[:,1:]\n",
    "y_test= y_test.iloc[:,1:]\n",
    "\n",
    "print(x_train.shape,x_test.shape, y_train.shape, y_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57637d91",
   "metadata": {
    "id": "57637d91"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score,roc_curve, auc\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc1d1a91",
   "metadata": {
    "id": "cc1d1a91"
   },
   "outputs": [],
   "source": [
    "def evaluate_perf(y_test,y_pred): # a function to evaluate the performance of a model\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp) #since the data is unbalanced\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    print('Specificity = {}'.format(specificity))\n",
    "    print('Recall = {}'.format(recall))\n",
    "    print(classification_report(y_test, y_pred, target_names=['0', '1']))\n",
    "    \n",
    "    return({'specificty':specificity, 'recall':recall})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de620388",
   "metadata": {
    "id": "de620388"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_forest = RandomForestClassifier(n_estimators=50, criterion='entropy')\n",
    "rand_forest.fit(x_train,y_train)\n",
    "\n",
    "y_pred_rf= rand_forest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745377d",
   "metadata": {
    "id": "6745377d",
    "outputId": "62511615-8310-4d47-8963-94b1e61fd90d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity = 0.9999218381920305\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evalrf= evaluate_perf(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2cf267",
   "metadata": {
    "id": "fd2cf267",
    "outputId": "bef7f39a-cb16-4cd8-f034-5fd959bf5624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Specificity = 0.9999457209666879\n",
      "Recall = 0.7332779393435812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "51\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.741587037806398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "52\n",
      "Specificity = 0.999924009353363\n",
      "Recall = 0.7336933942667221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "53\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7424179476526797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "54\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7366015787287079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "55\n",
      "Specificity = 0.9999174958693655\n",
      "Recall = 0.7474034067303698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "56\n",
      "Specificity = 0.9999261805146955\n",
      "Recall = 0.7353552139592854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "57\n",
      "Specificity = 0.9999457209666879\n",
      "Recall = 0.7320315745741587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "58\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7349397590361446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "59\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "60\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7341088491898629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "61\n",
      "Specificity = 0.9999109823853681\n",
      "Recall = 0.7482343165766514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "62\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "63\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7345243041130037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "64\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7386788533444121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "65\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7440797673452431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "66\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7461570419609472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "67\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7374324885749897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "68\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7453261321146656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "69\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7515579559617781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.88      0.93    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "70\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.731200664727877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7523888658080599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.88      0.93    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "72\n",
      "Specificity = 0.9999478921280204\n",
      "Recall = 0.7378479434981304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "73\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7382633984212713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "74\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7403406730369755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "75\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7399252181138346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "76\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7370170336518488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "77\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7461570419609472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "78\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7457415870378064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "79\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7370170336518488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "80\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7328624844204403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "81\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7440797673452431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "82\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7366015787287079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "83\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7436643124221022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "84\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7341088491898629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "85\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7361861238055671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "86\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7403406730369755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "87\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7403406730369755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "88\n",
      "Specificity = 0.9999478921280204\n",
      "Recall = 0.7299542999584545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.86      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "89\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7432488574989614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "90\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7424179476526797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "91\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "93\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7444952222683838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "94\n",
      "Specificity = 0.9999478921280204\n",
      "Recall = 0.7428334025758205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "95\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7432488574989614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "96\n",
      "Specificity = 0.999928351676028\n",
      "Recall = 0.7361861238055671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "97\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7428334025758205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "98\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7366015787287079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "99\n",
      "Specificity = 0.9999261805146955\n",
      "Recall = 0.7370170336518488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50,100):\n",
    "    print(i)\n",
    "    \n",
    "    rand_forest = RandomForestClassifier(n_estimators=i, criterion='entropy')\n",
    "    rand_forest.fit(x_train,y_train)\n",
    "    y_pred_rf= rand_forest.predict(x_test)\n",
    "    \n",
    "    evalrf= evaluate_perf(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b45ef7",
   "metadata": {
    "id": "99b45ef7",
    "outputId": "a2a70c00-9903-4431-d40e-627e1197d192"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7382633984212713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "101\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7428334025758205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "102\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7307852098047362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "103\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7370170336518488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "104\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.7345243041130037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "105\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7361861238055671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "106\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7357706688824263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "107\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7349397590361446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "108\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7374324885749897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "109\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7386788533444121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "110\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.7366015787287079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "111\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "112\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7349397590361446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "113\n",
      "Specificity = 0.999928351676028\n",
      "Recall = 0.7386788533444121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "114\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7353552139592854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "115\n",
      "Specificity = 0.9999261805146955\n",
      "Recall = 0.7345243041130037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "116\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7341088491898629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "117\n",
      "Specificity = 0.999928351676028\n",
      "Recall = 0.7465724968840881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "118\n",
      "Specificity = 0.9999457209666879\n",
      "Recall = 0.7353552139592854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "119\n",
      "Specificity = 0.9999261805146955\n",
      "Recall = 0.7440797673452431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "120\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7382633984212713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7436643124221022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "122\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7366015787287079\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "123\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7420024927295389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "124\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7403406730369755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "125\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7382633984212713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "126\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7436643124221022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "127\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7370170336518488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "128\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7424179476526797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "129\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7482343165766514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "130\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "131\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7440797673452431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "132\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7424179476526797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "133\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.7403406730369755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "134\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7374324885749897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "135\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7403406730369755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "136\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7457415870378064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "137\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.7361861238055671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "138\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7407561279601164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "139\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "140\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7490652264229332\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "141\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7357706688824263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7386788533444121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "143\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7399252181138346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "144\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7370170336518488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "145\n",
      "Specificity = 0.9999218381920305\n",
      "Recall = 0.7440797673452431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "146\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7345243041130037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "147\n",
      "Specificity = 0.999924009353363\n",
      "Recall = 0.7444952222683838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "148\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7424179476526797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "149\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "150\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7449106771915247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "151\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7382633984212713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "152\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "153\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "154\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7436643124221022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "155\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7361861238055671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "156\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.7341088491898629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "157\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "158\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7382633984212713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "159\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7432488574989614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "160\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7361861238055671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "161\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "162\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.741587037806398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity = 0.999928351676028\n",
      "Recall = 0.7436643124221022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "164\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7361861238055671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "165\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7407561279601164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "166\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "167\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.741587037806398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "168\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7428334025758205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "169\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7449106771915247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "170\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7374324885749897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "171\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "172\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.7361861238055671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "173\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7382633984212713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "174\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7395097631906938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "175\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7424179476526797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "176\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7420024927295389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "177\n",
      "Specificity = 0.9999478921280204\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "178\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7341088491898629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "179\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7436643124221022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "180\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7382633984212713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "181\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "182\n",
      "Specificity = 0.9999457209666879\n",
      "Recall = 0.7428334025758205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "183\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "185\n",
      "Specificity = 0.999928351676028\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "186\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7457415870378064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "187\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.741587037806398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "188\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7374324885749897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "189\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "190\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "191\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7449106771915247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "192\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7403406730369755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "193\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7432488574989614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "194\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.7444952222683838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "195\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7420024927295389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "196\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.741587037806398\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "197\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7440797673452431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "198\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "199\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7449106771915247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(100, 200):\n",
    "    print(i)\n",
    "    \n",
    "    rand_forest = RandomForestClassifier(n_estimators=i, criterion='entropy')\n",
    "    rand_forest.fit(x_train,y_train)\n",
    "    y_pred_rf= rand_forest.predict(x_test)\n",
    "    \n",
    "    evalrf= evaluate_perf(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c231e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d1c231e",
    "outputId": "284f5b1c-1a6f-4a0b-943b-f9eef986d1c9"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7332779393435812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "51\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7486497714997923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "52\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7299542999584545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.86      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "53\n",
      "Specificity = 0.999928351676028\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "54\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7432488574989614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "55\n",
      "Specificity = 0.9999218381920305\n",
      "Recall = 0.7424179476526797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "56\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7349397590361446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "57\n",
      "Specificity = 0.999924009353363\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "58\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7444952222683838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "59\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7420024927295389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "60\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7345243041130037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "61\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7328624844204403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "62\n",
      "Specificity = 0.9999218381920305\n",
      "Recall = 0.7378479434981304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "63\n",
      "Specificity = 0.999928351676028\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "64\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7378479434981304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "65\n",
      "Specificity = 0.999919667030698\n",
      "Recall = 0.7399252181138346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "66\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7316161196510179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "67\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7345243041130037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "68\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7386788533444121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "69\n",
      "Specificity = 0.999924009353363\n",
      "Recall = 0.7395097631906938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "70\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7382633984212713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "71\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7420024927295389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "72\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7353552139592854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "73\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7428334025758205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "74\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7320315745741587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "75\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7395097631906938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "76\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7299542999584545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.73      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.86      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "77\n",
      "Specificity = 0.9999261805146955\n",
      "Recall = 0.7353552139592854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "78\n",
      "Specificity = 0.9999413786440229\n",
      "Recall = 0.7357706688824263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "79\n",
      "Specificity = 0.999932693998693\n",
      "Recall = 0.7486497714997923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.75      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "80\n",
      "Specificity = 0.999919667030698\n",
      "Recall = 0.7424179476526797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "81\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7361861238055671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "82\n",
      "Specificity = 0.9999261805146955\n",
      "Recall = 0.7399252181138346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "83\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.739094308267553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "84\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7432488574989614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "85\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7449106771915247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "86\n",
      "Specificity = 0.9999435498053554\n",
      "Recall = 0.7386788533444121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "87\n",
      "Specificity = 0.9999370363213579\n",
      "Recall = 0.7399252181138346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "88\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7378479434981304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "89\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7420024927295389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "90\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7411715828832571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "91\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7432488574989614\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "92\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7399252181138346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "93\n",
      "Specificity = 0.9999305228373605\n",
      "Recall = 0.7420024927295389\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "94\n",
      "Specificity = 0.9999392074826904\n",
      "Recall = 0.7386788533444121\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "95\n",
      "Specificity = 0.9999544056120178\n",
      "Recall = 0.7357706688824263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "96\n",
      "Specificity = 0.9999457209666879\n",
      "Recall = 0.7382633984212713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.99      0.74      0.84      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "97\n",
      "Specificity = 0.9999348651600255\n",
      "Recall = 0.7424179476526797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    460583\n",
      "           1       0.98      0.74      0.85      2407\n",
      "\n",
      "    accuracy                           1.00    462990\n",
      "   macro avg       0.99      0.87      0.92    462990\n",
      "weighted avg       1.00      1.00      1.00    462990\n",
      "\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for i in range(50,100):\n",
    "    print(i)\n",
    "    \n",
    "    rand_forest = RandomForestClassifier(n_estimators=i, criterion='log_loss')\n",
    "    rand_forest.fit(x_train,y_train)\n",
    "    y_pred_rf= rand_forest.predict(x_test)\n",
    "    \n",
    "    evalrf= evaluate_perf(y_test,y_pred_rf)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
